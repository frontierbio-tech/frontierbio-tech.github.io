"use strict";(self.webpackChunkstudio=self.webpackChunkstudio||[]).push([[4427],{5904:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>u,frontMatter:()=>o,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"Processes/architecture","title":"Studio: Technical Overview","description":"Docker-Containerized Processing Architecture","source":"@site/docs/Processes/architecture.md","sourceDirName":"Processes","slug":"/Processes/architecture","permalink":"/docs/Processes/architecture","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Image Analysis","permalink":"/docs/Processes/analysis"}}');var i=r(4848),s=r(8453);const o={sidebar_position:5},t="Studio: Technical Overview",c={},l=[{value:"Docker-Containerized Processing Architecture",id:"docker-containerized-processing-architecture",level:2},{value:"AI Learning Workflow",id:"ai-learning-workflow",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"Docker-Based Infrastructure",id:"docker-based-infrastructure",level:2},{value:"GPU Training Workflow",id:"gpu-training-workflow",level:2},{value:"Dockerized Processing Workflow",id:"dockerized-processing-workflow",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"studio-technical-overview",children:"Studio: Technical Overview"})}),"\n",(0,i.jsx)(n.h2,{id:"docker-containerized-processing-architecture",children:"Docker-Containerized Processing Architecture"}),"\n",(0,i.jsx)(n.p,{children:"The Studio platform leverages Docker technology to create a consistent, reproducible environment for all computational processes, including tiling, training, inference, and analysis. This ensures students experience a reliable AI workflow without technical complexity. Data is seamlessly shared across various stages through carefully managed storage."}),"\n",(0,i.jsx)(n.h2,{id:"ai-learning-workflow",children:"AI Learning Workflow"}),"\n",(0,i.jsx)(n.p,{children:"The AI learning process guides students through clearly defined steps:"}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TD\n    subgraph "Student Learning Journey"\n        direction LR\n        A[Upload Raw Images] --\x3e B[Automated Tiling]\n        B --\x3e C[Annotation with Django Labeller]\n        C --\x3e D[Create Training Sets]\n        D --\x3e E[Configure Training Parameters]\n        E --\x3e F[Monitor Training Progress]\n        F --\x3e G[Evaluate Model Performance]\n        G --\x3e H[Deploy on New Images]\n        H --\x3e I[Analyze Results]\n    end'}),"\n",(0,i.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,i.jsx)(n.p,{children:"Studio operates with a user-friendly web interface connected to powerful backend services:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Web Browser"})," communicates with a ",(0,i.jsx)(n.strong,{children:"Caddy Server"}),", which manages secure connections."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Django Application"})," orchestrates tasks and manages data using a ",(0,i.jsx)(n.strong,{children:"PostgreSQL Database"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"RabbitMQ"})," coordinates communication and manages tasks between services."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Local Processing"})," tasks are handled on the main server, while ",(0,i.jsx)(n.strong,{children:"GPU-intensive tasks"})," are executed in Docker containers using external GPU resources."]}),"\n"]}),"\n",(0,i.jsx)(n.mermaid,{value:'graph TB\n    Client[Web Browser] --\x3e Caddy[Caddy Server]\n    Caddy --\x3e Django[Django Application]\n    Django --\x3e DB[(PostgreSQL Database)]\n    Django --\x3e RMQ[RabbitMQ]\n    RMQ --\x3e Worker1[Celery Worker]\n    RMQ --\x3e Worker2[Dockerized Worker for GPU Tasks]\n    Worker1 --\x3e LocalProcessing[Local Processing]\n    Worker2 --\x3e DockerLayer[Docker Container Layer]\n    DockerLayer --\x3e GPU[OVH AI GPU Resources]\n\n    subgraph "Main Server" \n        Caddy\n        Django\n        DB\n        RMQ\n        Worker1\n        LocalProcessing\n    end\n\n    subgraph "Docker Containerized Services"\n        Worker2\n        DockerLayer\n        GPU\n    end'}),"\n",(0,i.jsx)(n.h2,{id:"docker-based-infrastructure",children:"Docker-Based Infrastructure"}),"\n",(0,i.jsx)(n.p,{children:"The platform is structured around Docker containers, each specialized for different tasks:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Studio AI Container:"})," Manages the main Django application."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Caddy Container:"})," Provides secure, fast access to the web interface."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"RabbitMQ Container:"})," Facilitates communication between components."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Worker Containers:"})," Perform local and GPU-based tasks (tiling, training, inference, analysis)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Shared Volumes:"})," Store media and project data accessible by all containers."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"gpu-training-workflow",children:"GPU Training Workflow"}),"\n",(0,i.jsx)(n.p,{children:"Students configure and launch AI training through an intuitive interface:"}),"\n",(0,i.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant Student\n    participant Django as Django Platform\n    participant Queue as RabbitMQ\n    participant Worker as Docker Worker\n    participant Docker as Docker Container\n    participant GPU as OVH GPU Instance\n    participant Storage as Shared Volume\n\n    Student->>Django: Configure & Start Training\n    Django->>Storage: Store Training Configuration\n    Django->>Queue: Create Training Task\n    Queue->>Worker: Pick Up Task\n    Worker->>Storage: Mount Media Volume\n    Worker->>Docker: Create Training Container\n\n    loop Training Process\n        GPU->>GPU: Process Training Batches\n        GPU->>Storage: Save Model Checkpoints\n        Docker->>Worker: Report Metrics\n        Worker->>Django: Update Status\n        Django->>Student: Display Real-time Progress\n    end\n\n    GPU->>Storage: Save Final Trained Model\n    Docker->>Worker: Signal Completion\n    Worker->>Django: Update Task Status\n    Django->>Storage: Access Trained Model\n    Django->>Student: Present Training Results"}),"\n",(0,i.jsx)(n.h2,{id:"dockerized-processing-workflow",children:"Dockerized Processing Workflow"}),"\n",(0,i.jsx)(n.p,{children:"Studio uses a clear workflow for data processing:"}),"\n",(0,i.jsx)(n.mermaid,{value:'flowchart TD\n    subgraph "Shared Volume Structure"\n        direction TB\n        MediaVolume["/app/media"]\n        ProjectData["/app/media/projects"]\n        ImageData["/app/media/projects/project-{id}/input_images"]\n        TileData["/app/media/projects/project-{id}/annotations"]\n        ModelData["/app/media/projects/project-{id}/models"]\n        AnalysisData["/app/media/projects/project-{id}/analysis"]\n    end\n\n    subgraph "Tiling Process Container"\n        direction TB\n        T1[Mount Input Images] --\x3e T2[Process Into Tiles] --\x3e T3[Save Tiles to Volume]\n    end\n\n    subgraph "Training Process Container"\n        direction TB\n        M1[Mount Annotation Data] --\x3e M2[Train on GPU] --\x3e M3[Save Model to Volume]\n    end\n\n    subgraph "Inference Process Container"\n        direction TB\n        I1[Mount Model & Input Images] --\x3e I2[Run Inference] --\x3e I3[Save Results to Volume]\n    end\n\n    subgraph "Analysis Process Container"\n        direction TB\n        A1[Mount Inference Results] --\x3e A2[Process & Analyze] --\x3e A3[Generate Visualizations]\n    end\n\n    ImageData --\x3e T1\n    T3 --\x3e TileData\n    TileData --\x3e M1\n    M3 --\x3e ModelData\n    ModelData --\x3e I1\n    ImageData --\x3e I1\n    I3 --\x3e AnalysisData\n    AnalysisData --\x3e A1'}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(n.p,{children:"Studio simplifies complex AI workflows through Docker containerization, enabling students to focus on learning and practical AI development without extensive technical overhead. This design mirrors professional AI environments, ensuring real-world applicability and enhancing educational value."})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);