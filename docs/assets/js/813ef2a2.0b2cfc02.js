"use strict";(self.webpackChunkstudio=self.webpackChunkstudio||[]).push([[651],{126:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training_step2_new_job_button-25a0c524e83fd03ce7413e04770ae3eb.png"},290:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Processes/training","title":"Training Process","description":"Overview","source":"@site/docs/Processes/training.md","sourceDirName":"Processes","slug":"/Processes/training","permalink":"/docs/Processes/training","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Processes/training.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Annotation and Training Sets","permalink":"/docs/Processes/annotation"},"next":{"title":"Image Analysis","permalink":"/docs/Processes/analysis"}}');var r=i(4848),t=i(8453);const a={sidebar_position:3},o="Training Process",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Training Workflow",id:"training-workflow",level:2},{value:"Step 1: Select a Training Pipeline",id:"step-1-select-a-training-pipeline",level:2},{value:"Step 2: Create a New Training Job",id:"step-2-create-a-new-training-job",level:2},{value:"Step 3: Configure Job Parameters",id:"step-3-configure-job-parameters",level:2},{value:"Step 4: Start Training",id:"step-4-start-training",level:2},{value:"Step 5: Monitor Training Progress",id:"step-5-monitor-training-progress",level:2},{value:"Understanding Training Metrics",id:"understanding-training-metrics",level:2},{value:"Loss Values",id:"loss-values",level:3},{value:"Intersection over Union (IoU)",id:"intersection-over-union-iou",level:3},{value:"Typical Training Progress",id:"typical-training-progress",level:3},{value:"Step 6: View Completed Model",id:"step-6-view-completed-model",level:2},{value:"Model Architecture",id:"model-architecture",level:2},{value:"Training Process Behind the Scenes",id:"training-process-behind-the-scenes",level:2},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"training-process",children:"Training Process"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"The training process allows you to train segmentation models using your annotated image tiles. This guide focuses on the practical steps to create and monitor training jobs."}),"\n",(0,r.jsx)(n.h2,{id:"training-workflow",children:"Training Workflow"}),"\n",(0,r.jsx)(n.p,{children:"The ML training workflow follows these key steps:"}),"\n",(0,r.jsx)(n.mermaid,{value:"sequenceDiagram\n    actor User\n    participant Pipeline as Training Pipeline\n    participant Job as Training Job\n    participant Monitor as Training Monitor\n    participant Model as Trained Model\n    \n    User->>Pipeline: 1. Select pipeline\n    User->>Job: 2. Configure job parameters\n    User->>Job: 3. Start training\n    Job->>Monitor: 4. Process training data\n    User->>Monitor: 5. Monitor progress\n    Monitor->>Model: 6. Complete training\n    User->>Model: 7. Use model for analysis"}),"\n",(0,r.jsx)(n.h2,{id:"step-1-select-a-training-pipeline",children:"Step 1: Select a Training Pipeline"}),"\n",(0,r.jsx)(n.p,{children:"From the ML page, you can see available pipelines. Each pipeline is configured for a specific type of task."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Available Pipelines",src:i(3729).A+"",width:"1034",height:"459"})}),"\n",(0,r.jsx)(n.h2,{id:"step-2-create-a-new-training-job",children:"Step 2: Create a New Training Job"}),"\n",(0,r.jsx)(n.p,{children:'After selecting a pipeline, click the "New Job" button to create a new training task.'}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Create New Job",src:i(126).A+"",width:"1655",height:"768"})}),"\n",(0,r.jsx)(n.h2,{id:"step-3-configure-job-parameters",children:"Step 3: Configure Job Parameters"}),"\n",(0,r.jsx)(n.p,{children:"On the job configuration page, set up the parameters for your training:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Configure Training Job",src:i(970).A+"",width:"781",height:"770"})}),"\n",(0,r.jsx)(n.p,{children:"Key parameters include:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Training Set"}),": Select your annotated tile set"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"From Model"})," (optional): Use a previous model as a starting point"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Size"}),": Number of images to process at once (default: 8)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Number of Epochs"}),": Total training iterations (default: 10-50)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Architecture"}),": Neural network architecture to use"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning Rate"}),": Step size for model optimization (default: 0.001)"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-4-start-training",children:"Step 4: Start Training"}),"\n",(0,r.jsx)(n.p,{children:'Click "Start Training" to begin the training process.'}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Start Training",src:i(9792).A+"",width:"1339",height:"473"})}),"\n",(0,r.jsx)(n.h2,{id:"step-5-monitor-training-progress",children:"Step 5: Monitor Training Progress"}),"\n",(0,r.jsx)(n.p,{children:"During training, you can monitor progress and metrics in real-time:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Monitor Training",src:i(5085).A+"",width:"1059",height:"866"})}),"\n",(0,r.jsx)(n.p,{children:"The monitoring interface shows:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Overall Progress"}),": Percentage of training completed"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loss Graph"}),": Shows how well the model is learning","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Training loss (blue): Error on training data"}),"\n",(0,r.jsx)(n.li,{children:"Validation loss (red): Error on validation data"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"IoU Graph"}),": Shows segmentation accuracy","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Training IoU (blue): Accuracy on training data"}),"\n",(0,r.jsx)(n.li,{children:"Validation IoU (red): Accuracy on validation data"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"understanding-training-metrics",children:"Understanding Training Metrics"}),"\n",(0,r.jsx)(n.h3,{id:"loss-values",children:"Loss Values"}),"\n",(0,r.jsx)(n.p,{children:"The loss curves show how well the model is learning:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Decreasing loss = model is improving"}),"\n",(0,r.jsx)(n.li,{children:"Flattening loss = learning is slowing down"}),"\n",(0,r.jsx)(n.li,{children:"Increasing validation loss = potential overfitting"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"intersection-over-union-iou",children:"Intersection over Union (IoU)"}),"\n",(0,r.jsx)(n.p,{children:"IoU measures the accuracy of segmentation:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"IoU = Area of Overlap / Area of Union"}),"\n",(0,r.jsx)(n.li,{children:"Values range from 0 to 1 (higher is better)"}),"\n",(0,r.jsx)(n.li,{children:"Values above 0.8 generally indicate good segmentation"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"typical-training-progress",children:"Typical Training Progress"}),"\n",(0,r.jsx)(n.p,{children:"A successful training run shows these patterns:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Epoch 1/50:\n  Train Loss: 0.4920, Train IoU: 0.3247\n  Val Loss: 0.4455, Val IoU: 0.4499\n\nEpoch 25/50:\n  Train Loss: 0.0411, Train IoU: 0.8979\n  Val Loss: 0.0536, Val IoU: 0.8759\n\nEpoch 50/50:\n  Train Loss: 0.0417, Train IoU: 0.8503\n  Val Loss: 0.0563, Val IoU: 0.8750\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Epoch",src:i(3693).A+"",width:"417",height:"608"})}),"\n",(0,r.jsx)(n.h2,{id:"step-6-view-completed-model",children:"Step 6: View Completed Model"}),"\n",(0,r.jsx)(n.p,{children:"Once training completes, the model is automatically saved and becomes available for analysis tasks."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Completed Model",src:i(5018).A+"",width:"735",height:"786"})}),"\n",(0,r.jsx)(n.h2,{id:"model-architecture",children:"Model Architecture"}),"\n",(0,r.jsx)(n.p,{children:"The default model architecture is UperNet with ConvNeXt-base backbone, which is effective for segmentation tasks:"}),"\n",(0,r.jsx)(n.mermaid,{value:"graph TD\n    A[Input Image] --\x3e B[ConvNeXt Backbone]\n    B --\x3e C[Feature Pyramid Network]\n    C --\x3e D[UperNet Decoder]\n    D --\x3e E[Segmentation Output]"}),"\n",(0,r.jsx)(n.p,{children:"UperNet combines:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Powerful CNN backbone (ConvNeXt)"}),"\n",(0,r.jsx)(n.li,{children:"Multi-scale feature extraction"}),"\n",(0,r.jsx)(n.li,{children:"Effective decoder for detailed segmentation"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"training-process-behind-the-scenes",children:"Training Process Behind the Scenes"}),"\n",(0,r.jsx)(n.p,{children:"While you don't need to understand all technical details, here's a simplified view of what happens during training:"}),"\n",(0,r.jsx)(n.mermaid,{value:"flowchart TD\n    A[Prepare Training Data] --\x3e B[Convert Annotations to Masks]\n    B --\x3e C[Split Data into Training/Validation]\n    C --\x3e D[Initialize Model Architecture]\n    D --\x3e E[Training Loop]\n    E --\x3e F[Calculate Loss]\n    F --\x3e G[Update Model Weights]\n    G --\x3e H[Evaluate on Validation Data]\n    H --\x3e I{Continue?}\n    I --\x3e|Yes| E\n    I --\x3e|No| J[Save Final Model]"}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsx)(n.p,{children:"For optimal training results:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Quality Annotations"}),": Ensure annotations are accurate and consistent"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sufficient Data"}),": Include at least 50-100 annotated tiles in your training set"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Diverse Examples"}),": Include various examples that represent what you want to detect"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitor Validation Metrics"}),": Watch for signs of overfitting (validation loss increases while training loss decreases)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Iteration"}),": Start with default parameters, then create new jobs with adjusted parameters based on results"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Transfer Learning"}),": For incremental improvements, use a previous model as a starting point"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},970:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training_step3_configure_job-960c822ad975d4de74ec69a85d921193.png"},3693:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/5.1_process-abd7a2b8d287403238a09c9c2d0344d8.png"},3729:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training_step1_select_pipeline-2462125224e4249c3520b0741accc6ad.png"},5018:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training_step6_complete-0592357f24c3ecc90eb1bb30cc48f43d.png"},5085:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training_step5_monitor_training-73682067240abbbe2bbb310ff21173e6.png"},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}},9792:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/training_step4_start_training-29c1e291cc08a744ffdc44520cb9659c.png"}}]);